{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module 클래스를 사용하여 SSD 모델 아키텍처를 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSD, self).__init__()\n",
    "        # Define the backbone network\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Define the convolutional layers for object detection\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        ])\n",
    "        # Define the detection heads for object detection\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Conv2d(512, 4 * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(512, 6 * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, 6 * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(256, 6 * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(128, 6 * 4, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(128, 6 * 4, kernel_size=3, padding=1)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "위의 코드에서 우리는 13계층 백본 네트워크와 6개의 컨볼루션 계층 및 6개의 탐지 헤드를 정의합니다. 백본 네트워크는 일련의 컨벌루션 및 최대 풀링 레이어로 구성되며 입력 이미지에서 기능을 추출하도록 설계되었습니다. 컨벌루션 레이어와 감지 헤드는 객체 감지에 사용되며 각 헤드는 서로 다른 스케일에서 객체의 클래스와 위치를 예측합니다.\n",
    "\n",
    "\n",
    "다음으로 입력 이미지가 주어진 모델의 출력을 계산하는 SSD 모델의 전달 방법을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    # Pass\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
